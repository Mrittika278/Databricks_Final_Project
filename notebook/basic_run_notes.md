
# Initial PySpark Practice with Self-Generated Dataset
-----------------------------------------
## Objective
I built this initial exercise to understand the fundamentals of PySpark and Databricks by creating a small dataset directly inside a notebook, without using any external data sources.

-----------------------------------------
## Dataset Creation
I programmatically created a small sample dataset using Spark DataFrames to simulate basic e-commerce transactions, including attributes such as customer name, product category, and purchase amount.

-----------------------------------------
## Operations Performed
- I created a Spark DataFrame from in-memory data  
- I inspected the schema and verified row counts  
- I performed basic data quality checks for null and invalid values  
- I applied simple filtering and cleaning logic  
- I used group-by aggregations to compute basic metrics  
-----------------------------------------
## Learning Outcome
This exercise helped me gain confidence in working with Spark DataFrames, understand the difference between transformations and actions, and practice core analytical operations in Databricks before moving on to a larger real-world dataset.
